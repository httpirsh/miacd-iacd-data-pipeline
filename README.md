# CO2 Data Engineering Pipeline

A complete data engineering pipeline for analyzing global CO2 emissions using **Kafka, Spark, PostgreSQL, and Superset** deployed on **Kubernetes**.

---

## ğŸ“Š Project Overview

### Dataset
**Source:** Our World in Data - CO2 Emissions Dataset

| Aspect | Original | Processed |
|--------|----------|-----------|
| **Rows** | 50,407 | 23,405 (1900-2014 filtered) |
| **Columns** | 79 | 7 (selected variables) |
| **Size** | 14MB | 1.4MB |
| **Time Range** | 1750-2014 | 1900-2014 (115 years) |
| **Data Quality** | Sparse pre-1900 | Dense, complete |

### Selected Variables (7 columns)
1. `country` - Country name
2. `year` - Year (1900-2014)
3. `iso_code` - ISO 3-letter country code
4. `population` - Population
5. `gdp` - Gross Domestic Product
6. `co2` - Total CO2 emissions (million tonnes)
7. `co2_per_capita` - Per capita emissions (tonnes)

**Rationale**: Focused on time-series analysis, country comparisons, GDP-emissions correlation, and geographic visualizations. Pre-1900 data was removed due to significant gaps and missing values.

---

## ğŸ—ï¸ Architecture

### Components
1. **Apache Kafka** (KRaft mode) - Message broker for streaming
2. **Apache Spark** (Master + Worker) - Data processing engine
3. **PostgreSQL** - Relational database for storage
4. **Apache Superset** - Data visualization dashboards

### Data Flow
```
CSV (23K rows, 7 cols) â†’ Kafka Producer â†’ Kafka Topic (co2-raw)
                              â†“
                        Spark Consumer â†’ PostgreSQL (3 tables)
                              â†“
                        Superset Dashboards
```

**Alternative**: Direct batch load via `batch_processing.py` (CSV â†’ Spark â†’ PostgreSQL)

---

## ğŸ“‚ Database Schema

### Tables
1. **raw_emissions** (7 columns)
   - All raw data: country, year, iso_code, population, gdp, co2, co2_per_capita
   
2. **country_summary** (aggregated by country)
   - Total CO2, avg per capita, rankings, latest year data
   
3. **yearly_summary** (aggregated by year)
   - Global totals, growth rates, country counts

### Views
- **top_polluters** - Top 10 countries by total CO2
- **top_per_capita** - Top 10 by per capita emissions
- **recent_trends** - Last 20 years of global data

---

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ README.md                   # This file - Project overview
â”œâ”€â”€ STATUS.md                   # Current deployment status & next steps
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ owid-co2-data.csv       # Original dataset (14MB, archived)
â”‚   â””â”€â”€ reduced_co2.csv         # 7 columns, 23,405 rows (1900-2014)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ extract_reduced.py      # Dataset extraction & filtering
â”œâ”€â”€ kafka/
â”‚   â”œâ”€â”€ producer.py             # Kafka producer (â†’ co2-raw topic)
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ consumer.py             # Kafka â†’ PostgreSQL streaming
â”‚   â”œâ”€â”€ batch_processing.py     # CSV â†’ PostgreSQL batch load
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ schema.sql              # 7 columns, 3 tables, 3 views
â””â”€â”€ kubernetes/                 # Deployment manifests
    â”œâ”€â”€ kafka-kraft.yaml
    â”œâ”€â”€ postgres.yaml
    â”œâ”€â”€ spark-master.yaml
    â”œâ”€â”€ spark-worker.yaml
    â””â”€â”€ superset.yaml
```

---

## ğŸš€ Quick Start (Kubernetes/Minikube)

### Prerequisites
- Minikube
- kubectl
- Python 3.8+

### 1. Start Minikube
```bash
minikube start --cpus=2 --memory=4096
```

### 2. Deploy all components
```bash
cd kubernetes
kubectl apply -f kafka-kraft.yaml
kubectl apply -f postgres.yaml
kubectl apply -f spark-master.yaml
kubectl apply -f spark-worker.yaml
kubectl apply -f superset.yaml
```

### 3. Wait for pods to be ready
```bash
kubectl get pods -w
# Wait until all pods show "Running"
```

### 4. Initialize PostgreSQL schema
```bash
kubectl port-forward postgres-0 5432:5432 &
PGPASSWORD=co2_password psql -h localhost -U co2_user -d co2_data -f sql/schema.sql
```

### 5. Create Kafka topic
```bash
kubectl exec -it kafka-0 -- kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --topic co2-raw \
  --partitions 3 --replication-factor 1
```

### 6. Load data (Option A: Batch)
```bash
# Get Spark master pod name
SPARK_POD=$(kubectl get pods -l app=spark-master -o jsonpath='{.items[0].metadata.name}')

# Copy CSV file
kubectl cp data/reduced_co2.csv $SPARK_POD:/tmp/

# Run batch processing
kubectl exec -it $SPARK_POD -- spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark-apps/batch_processing.py
```

### 7. Access Superset
```bash
kubectl port-forward svc/superset 8088:8088
# Open http://localhost:8088
# Login: admin/admin
```

**Add PostgreSQL connection in Superset:**
- Host: `postgres.default.svc.cluster.local`
- Port: `5432`
- Database: `co2_data`
- Username: `co2_user`
- Password: `co2_password`

## ğŸ“Š Database Schema

### Tables (7 columns matching CSV)
1. **raw_emissions** - All data from Kafka stream
   - country, year, iso_code, population, gdp, co2, co2_per_capita
2. **country_summary** - Aggregated by country (totals, rankings)
3. **yearly_summary** - Aggregated by year (global trends)

### Views
- `top_polluters` - Top 10 countries by total CO2
- `top_per_capita` - Top 10 by per capita emissions
- `recent_trends` - Last 20 years

## ğŸ”§ Useful Commands (Kubernetes)

### Check pod status
```bash
kubectl get pods
kubectl describe pod <pod-name>
kubectl logs <pod-name>
```

### Create Kafka topic
```bash
kubectl exec -it kafka-0 -- kafka-topics.sh \
  --list \
  --bootstrap-server localhost:9092
```

### Monitor Kafka messages
```bash
kubectl exec -it kafka-0 -- kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic co2-raw \
  --from-beginning \
  --max-messages 10
```

### Connect to PostgreSQL
```bash
kubectl port-forward postgres-0 5432:5432
PGPASSWORD=co2_password psql -h localhost -U co2_user -d co2_data
```

### Query data
```sql
-- Count records
SELECT COUNT(*) FROM raw_emissions;

-- Top 10 polluters
SELECT * FROM top_polluters;

-- Recent global trends
SELECT * FROM recent_trends;
```

### Check Spark jobs
```bash
# Port-forward Spark Master UI
kubectl port-forward svc/spark-master 8080:8080
# Open http://localhost:8080
```

## ğŸ“ˆ Superset Dashboards

### Dashboard Ideas
1. **Global Overview**
   - Line chart: Global CO2 over time
   - Area chart: Emission sources (coal, oil, gas)

2. **Country Rankings**
   - Bar chart: Top 10 total polluters
   - Bar chart: Top 10 per capita
   - Table: All countries ranked

3. **Trends Analysis**
   - Scatter: GDP vs CO2
   - Line chart: YoY growth rates
   - Heatmap: Regional emissions

## ğŸ§ª Testing

### Test producer only
```bash
python kafka/producer.py --max-records 100
```

### Test database connection
```bash
docker exec -it postgres psql -U co2_user -d co2_data -c "SELECT COUNT(*) FROM raw_emissions;"
```

### Test Spark locally
```bash
cd spark
pip install -r requirements.txt
python aggregation_job.py
```

## ğŸ“ Development Workflow

1. **Week 1**: Set up Docker Compose environment
2. **Week 2**: Implement and test Kafka producer/consumer
3. **Week 3**: Develop Spark processing jobs
4. **Week 4**: Create Superset dashboards
5. **Week 5**: Deploy to Kubernetes and test

## ğŸ› ï¸ Troubleshooting

### Kafka not receiving messages
- Check if topic exists: `kubectl exec -it kafka-0 -- kafka-topics.sh --list --bootstrap-server localhost:9092`
- Check producer logs for errors
- Verify port-forward is active: `kubectl port-forward kafka-0 9092:9092`

### Spark consumer not writing to PostgreSQL
- Check PostgreSQL is running: `kubectl get pods | grep postgres`
- Verify JDBC URL uses internal service name: `postgres.default.svc.cluster.local`
- Check Spark logs: `kubectl logs <spark-master-pod>`

### Superset can't connect to PostgreSQL
- Use hostname `postgres.default.svc.cluster.local` (not localhost)
- Verify credentials: co2_user/co2_password
- Check if PostgreSQL pod is running

### Out of memory errors
- Check Minikube resources: `minikube config get memory`
- Reduce Spark worker replicas or memory requests
- Current setup uses 512Mi per Spark pod

### Pod stuck in CrashLoopBackOff
- Check logs: `kubectl logs <pod-name>`
- Describe pod: `kubectl describe pod <pod-name>`
- Verify image versions are correct (apache/kafka:4.1.0, apache/spark:4.0.1)

## ğŸ¯ Success Criteria

- âœ… 23K+ records loaded from reduced CSV
- âœ… Data cleaned and transformed by Spark
- âœ… PostgreSQL contains all 3 tables with data
- âœ… Superset displays interactive dashboards
- âœ… All 5 components running on Kubernetes
- âœ… Pipeline processes data efficiently

## ğŸ“š Resources

- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [Spark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)
- [Superset Documentation](https://superset.apache.org/docs/intro)
- [Dataset Source](https://github.com/owid/co2-data)
- [Kubernetes Documentation](https://kubernetes.io/docs/home/)

---

## ï¿½ Implementation Summary

### Completed
âœ… Dataset reduced from 79 â†’ 7 columns (1900-2014 filtered)  
âœ… Kafka producer for streaming CSV data  
âœ… 2 Spark jobs: batch processing + streaming consumer  
âœ… PostgreSQL schema (7 columns, 3 tables, 3 views)  
âœ… All 5 components deployed to Kubernetes  
âœ… Minikube cluster running with all pods active  

### Simplifications Made
- Removed Docker Compose (Kubernetes-only deployment)
- Schema perfectly matches dataset (7 columns everywhere)
- Eliminated duplicate/redundant code (304 lines removed)
- Consolidated to 2 documentation files (README + STATUS)

### Current Phase
ï¿½ **Week 4**: Database initialization â†’ Data loading â†’ Dashboard creation

### Technical Specs
- **Deployment**: Kubernetes/Minikube (2 CPUs, 4GB RAM)
- **Images**: apache/kafka:4.1.0, apache/spark:4.0.1, postgres:latest
- **Data**: 23,405 rows Ã— 7 columns (1900-2014)
- **Storage**: 12Gi total PVCs (Kafka 5Gi, PostgreSQL 5Gi, Superset 2Gi)

---

## ğŸ‘¥ Project

**IACD** - Data Engineering Pipeline  
**Deployment**: Kubernetes  
**Status**: âœ… Data loaded & analyzed | ğŸ”„ Dashboards ready to create

---

## ğŸ“Š Quick Start Guide

### 1ï¸âƒ£ View Analysis Results
```bash
# See comprehensive findings
cat ANALYSIS.md
```
**Key Findings**:
- âœ… Global CO2 increased 17x from 1900 to 2024
- âœ… COVID caused -4.7% drop (2020) but fully recovered
- âœ… USA leads historically (425K Mt), China leads currently (12.3K Mt)
- âœ… China & India showed explosive growth (+237%, +224% since 2000)

### 2ï¸âƒ£ Access Superset Dashboards
```bash
# Superset is running and port-forwarded
open http://localhost:8088

# Login: admin / admin
```

**Follow these guides**:
- ğŸ“˜ **SUPERSET_SETUP.md** - Complete dashboard creation guide (12 charts)
- ğŸ“— **DASHBOARD_QUICK_START.md** - Quick reference for top 10 charts
- ğŸ“™ **sql/superset_queries.sql** - 12 categories of ready-to-use queries

### 3ï¸âƒ£ Query Data Directly
```bash
# PostgreSQL is running and port-forwarded
PGPASSWORD=co2_password psql -h localhost -U co2_user -d co2_data

# Example queries
SELECT * FROM top_polluters LIMIT 10;
SELECT * FROM recent_trends;
SELECT year, total_global_co2 FROM yearly_summary WHERE year >= 2018;
```

### 4ï¸âƒ£ Optional: Test Kafka Streaming
```bash
# Producer (streams CSV to Kafka)
python kafka/producer.py

# See STATUS.md for Spark consumer commands
```

---

## ğŸ“š Documentation Index

| Document | Purpose | Use When |
|----------|---------|----------|
| **README.md** (this file) | Project overview & architecture | First time setup |
| **STATUS.md** | Current deployment status | Checking what's running |
| **ANALYSIS.md** | Complete data insights | Presenting findings |
| **SUPERSET_SETUP.md** | Full dashboard guide (7 sections) | Creating visualizations |
| **DASHBOARD_QUICK_START.md** | Quick chart reference | Building specific charts |
| **sql/superset_queries.sql** | Pre-built SQL queries | Custom analysis |

---

## ğŸ¯ Current Status

âœ… **Infrastructure**: All 5 pods running (Kafka, Spark Master, Spark Worker, PostgreSQL, Superset)  
âœ… **Data Loaded**: 23,405 rows (1900-2024, 247 countries, 7 variables)  
âœ… **Tables Created**: raw_emissions, country_summary, yearly_summary + 3 views  
âœ… **Analysis Complete**: See `ANALYSIS.md` for findings  
âœ… **Port-Forwards Active**: PostgreSQL (5432), Superset (8088)  
ğŸ”„ **Dashboards**: Ready to create (follow `SUPERSET_SETUP.md`)  

See [`STATUS.md`](STATUS.md) for detailed deployment information.

---

**Last Updated**: November 16, 2025
